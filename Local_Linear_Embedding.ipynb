{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn import manifold\n",
    "from sklearn import neighbors\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data from zipped mnist files into numpy arrays\n",
    "# Modified from source: https://gist.github.com/tylerneylon/ce60e8a06e7506ac45788443f7269e40\n",
    "#\n",
    "# Input:  filename --> Zipped file to parse\n",
    "#\n",
    "# Output: return   --> Numpy array of unint8 data points\n",
    "#\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename) as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an nxm matrix of evenly distributed samples from an input sample set\n",
    "#\n",
    "# Inputs: Y    --> Sample matrix\n",
    "#         n, m --> Landmark matrix dimensions\n",
    "#\n",
    "# Output: idx  --> nxm Landmark matrix\n",
    "#\n",
    "def find_landmarks(Y, n, m):\n",
    "    xr = np.linspace(np.min(Y[:,0]), np.max(Y[:,0]), n)\n",
    "    yr = np.linspace(np.min(Y[:,1]), np.max(Y[:,1]), m)\n",
    "    xg, yg = np.meshgrid(xr, yr)\n",
    "    idx = [0]*(n*m)\n",
    "    for i, x, y in zip(range(n*m), xg.flatten(), yg.flatten()):\n",
    "        idx[i] = int(np.sum(np.abs(Y-np.array([x,y]))**2, axis=-1).argmin())\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: x --> the basis vector (784 x 1)\n",
    "#         E --> eta is the matrix of nearest neighbors (k x 784)\n",
    "# \n",
    "# Outputs: C --> the covariance matrix of the nearest neighbors of the vector x \n",
    "#\n",
    "# Iterate theough the nearest neighbors and compute the  \n",
    "#\n",
    "def calc_covariance(Eta):\n",
    "    print(\"Calculate covariance:\")\n",
    "    print(\"E: \", np.shape(Eta))\n",
    "    \n",
    "    # Compute the local covariance matrix\n",
    "    C = np.cov(Eta)\n",
    "\n",
    "    print(\"Local covariance matrix C: \", np.shape(C))\n",
    "\n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear non-neighbor weight entries from the weight vector\n",
    "#\n",
    "# Inputs:  nbrs --> the list of nearest neighbors\n",
    "#          wght --> the calculated weight vector\n",
    "# \n",
    "# Outputs: wght --> the adjusted weight vector    \n",
    "#\n",
    "def clear_non_neighbors(nbrs, wght):\n",
    "    print(\"Clear non-nieghbors:\")\n",
    "    print(\"wght: \", np.shape(wght), \" - \", wght)\n",
    "    \n",
    "    # Create mask vector\n",
    "    dim = np.shape(wght)[0]\n",
    "    mask = np.ones(dim)                        # ones mean, discard the value\n",
    "    print(\"Mask: \", np.shape(mask), \" - \", mask)\n",
    "\n",
    "    # Apply zeros to the nearest neighbors so we keep the weights\n",
    "    dim_nbrs = np.shape(nbrs)[1]\n",
    "    print(\"dim nbrs: \", dim_nbrs)\n",
    "    for i in range(0, dim_nbrs):\n",
    "        mask[nbrs[0,i]] = 0;\n",
    "        #print(\"nbr: \", nbrs[0,i])\n",
    "        \n",
    "    # mask off the non-neighbor weights\n",
    "    w = ma.masked_array(wght, mask)\n",
    "    print(w)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale weight values for nearest neighbors\n",
    "#\n",
    "# Inputs:  wght --> the wight vector with non-neighbors blanked out\n",
    "# \n",
    "# Outputs: w    --> the adjusted weight vector    \n",
    "#\n",
    "def scale_neighbors(wght):\n",
    "    sumw = np.sum(wght)\n",
    "    w = wght / sumw\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Determine the reconstruction weights for each X\n",
    "#\n",
    "# Inputs:  X    --> Data Matrix\n",
    "#          v    --> Index into the data matrix for the vector we want to construct weights for\n",
    "#          tree --> nearest neighbors tree\n",
    "#          k    --> number of nearest neighbors  \n",
    "# \n",
    "# Outputs: W    --> the weight matrix\n",
    "#\n",
    "def construct_weight_vector(X, v, nbrs, k):\n",
    "    # Setup matrices and variables\n",
    "    D = np.shape(X)[1]                              # get the dimension of X\n",
    "    print(\"Construct weight matrix\")\n",
    "    print(\"X = \", np.shape(X))\n",
    "    print(\"D = \", D)\n",
    "    print(\"k = \", k)\n",
    "    print(\"Image #\", v, \"(v)\")\n",
    "    print(\"Neighbors = \", nbrs)\n",
    "\n",
    "    # Build a matrix of the nearest neighbors\n",
    "    # (this is all neighbors of the vector v, so remove all others from X)\n",
    "    Eta = np.delete(X, v, axis=0) \n",
    "    #print(\"Eta: \", np.shape(Eta))\n",
    "    \n",
    "    # Compute local covariance matrix for the vector v in X and all neighbors\n",
    "    C = calc_covariance(Eta)\n",
    "\n",
    "    # Solve the linear system with constraint that rows of weights sum to one\n",
    "    b = np.ones(np.shape(C)[1])  # build the constant vector\n",
    "    w = np.linalg.solve(C, b)    # compute solution\n",
    "    \n",
    "    # Apply first constraint to zero out non-neighbor weights\n",
    "    w = clear_non_neighbors(nbrs, w)\n",
    "    \n",
    "    # Apply second constraint to scale valid neighbors\n",
    "    w = scale_neighbors(w)\n",
    "    \n",
    "    print(\"w: \", np.shape(w))\n",
    "    #print(w)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find bottom d+1 eigenvectors of M\n",
    "#  (corresponding to the d+1 smallest eigenvalues) \n",
    "#set the qth ROW of Y to be the q+1 smallest eigenvector\n",
    "#  (discard the bottom eigenvector [1,1,1,1...] with eigenvalue zero)\n",
    "def compute_embedding_components(W, d):\n",
    "    print(\"Compute embedding components:\")\n",
    "    #create sparse matrix M = (I-W)'*(I-W)\n",
    "    I = np.identity(np.shape(W)[0])\n",
    "    M = mul((I - W).T, (I - W))\n",
    "\n",
    "    # Find the bottom d + 1 eigenvectors\n",
    "    U, S, Vt = np.linalg.svd(M)\n",
    "    \n",
    "    print(\"U: \", np.shape(U))\n",
    "    print(\"S: \", np.shape(S))\n",
    "    print(\"Vt: \", np.shape(Vt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nearest_neighbors(X, n_neighbors, n_components):\n",
    "    tree = neighbors.BallTree(X, leaf_size=n_components)\n",
    "    dist, ind = tree.query(X, k=n_neighbors)\n",
    "    print(\"ind: \", np.shape(ind))\n",
    "    return dist, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO - We only have to implement this function, swap it with the manifold one below\n",
    "# Seek a low-rank projection on an input matrix\n",
    "#\n",
    "# Inputs: X            --> Input matrix to reduce\n",
    "#         n_neighbors  --> Maximum number of neighbors used for reconstruction\n",
    "#         n_components --> Maximum number of linearly independent components for reconstruction\n",
    "#\n",
    "# Output: Y            --> Reconstructed vectors in a lower rank\n",
    "#         err          --> (Optional implementation) Error margin of vectors\n",
    "#\n",
    "def locally_linear_embedding(X, n_neighbors, n_components):\n",
    "    \n",
    "    # Step 1: Find the nearest neighbors at for each sample\n",
    "    #tree = neighbors.BallTree(X, leaf_size=n_components)\n",
    "    #dist, ind = tree.query(X[:1], k=n_neighbors)\n",
    "    dist, ind = compute_nearest_neighbors(X, n_neighbors, n_components)\n",
    "    \n",
    "    # Step 2: Construct a weight matrix that recreates X from its neighbors\n",
    "    n = np.shape(X)[0]\n",
    "    d = np.shape(X)[1]\n",
    "    print(\"n: \", n)\n",
    "    print(\"d: \", d)\n",
    "    W = np.zeros([n,n-1])\n",
    "    print(\"Weight matrix: \", np.shape(W))\n",
    "\n",
    "    # Loop through each image and construct its weight matrix \n",
    "    rows = np.shape(X)[0]\n",
    "\n",
    "\n",
    "    \n",
    "    for r in range(0, rows - 1):\n",
    "        print(\"Row: \",r)\n",
    "        print(\"ind: \", ind[r,:])\n",
    "        w = construct_weight_vector(X, r, ind[r,:], n_neighbors)\n",
    "        W[r,:] = w[:]\n",
    "    \n",
    "    Y = X[:,0:2]   # placeholder\n",
    "    err = 0.001    # placeholder\n",
    "    return Y, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mnist data from files\n",
    "raw_train = read_idx(\"train-images-idx3-ubyte.gz\")\n",
    "train_data = np.reshape(raw_train, (60000, 28*28))\n",
    "train_label = read_idx(\"train-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ind:  (5851, 10)\n",
      "n:  5851\n",
      "d:  784\n",
      "Weight matrix:  (5851, 5850)\n",
      "Row:  0\n",
      "ind:  [   0 2748 2880  507  953  605   53 2749 1731   84]\n",
      "Construct weight matrix\n",
      "X =  (5851, 784)\n",
      "D =  784\n",
      "k =  10\n",
      "Image # 0 (v)\n",
      "Neighbors =  [   0 2748 2880  507  953  605   53 2749 1731   84]\n",
      "Calculate covariance:\n",
      "E:  (5850, 784)\n",
      "Local covariance matrix C:  (5850, 5850)\n",
      "Clear non-nieghbors:\n",
      "wght:  (5850,)  -  [-1.61775427e+11 -1.18422215e+13  1.60772734e+13 ... -1.53378515e+12\n",
      " -3.50573757e+12 -3.54713744e+12]\n",
      "Mask:  (5850,)  -  [1. 1. 1. ... 1. 1. 1.]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-642fa61a67cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_label\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Y, err = manifold.locally_linear_embedding(X, n_neighbors=10, n_components=2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocally_linear_embedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_components\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_landmarks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-b8a9cd3aa338>\u001b[0m in \u001b[0;36mlocally_linear_embedding\u001b[1;34m(X, n_neighbors, n_components)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Row: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ind: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconstruct_weight_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mind\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-2598c7c3a43b>\u001b[0m in \u001b[0;36mconstruct_weight_vector\u001b[1;34m(X, v, nbrs, k)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# Apply first constraint to zero out non-neighbor weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclear_non_neighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Apply second constraint to scale valid neighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-5ba26d1034be>\u001b[0m in \u001b[0;36mclear_non_neighbors\u001b[1;34m(nbrs, wght)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Apply zeros to the nearest neighbors so we keep the weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mdim_nbrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dim nbrs: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_nbrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim_nbrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "# Train algorithm and calculate landmark graph\n",
    "X = train_data[train_label == 8]\n",
    "#Y, err = manifold.locally_linear_embedding(X, n_neighbors=10, n_components=2)\n",
    "Y, err = locally_linear_embedding(X, n_neighbors=10, n_components=2)\n",
    "landmarks = find_landmarks(Y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clustered data with landmarks overlaid\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.scatter(Y[landmarks,0], Y[landmarks,1])\n",
    "\n",
    "# Show the landmark samples in a 5x5 grid\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i in range(len(landmarks)):\n",
    "    ax = fig.add_subplot(5, 5, i+1)\n",
    "    imgplot = ax.imshow(np.reshape(X[landmarks[i]], (28,28)), cmap=plt.cm.get_cmap(\"Greys\"))\n",
    "    imgplot.set_interpolation(\"nearest\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
