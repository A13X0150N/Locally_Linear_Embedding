{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "#matplotlib inline\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "from numpy import matmul as mul\n",
    "import scipy as sp\n",
    "from sklearn import manifold\n",
    "from sklearn import neighbors\n",
    "from sklearn import datasets\n",
    "import struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse data from zipped mnist files into numpy arrays\n",
    "# Modified from source: https://gist.github.com/tylerneylon/ce60e8a06e7506ac45788443f7269e40\n",
    "#\n",
    "# Input:  filename --> Zipped file to parse\n",
    "#\n",
    "# Output: return   --> Numpy array of unint8 data points\n",
    "#\n",
    "def read_idx(filename):\n",
    "    with gzip.open(filename) as f:\n",
    "        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n",
    "        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n",
    "        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct an nxm matrix of evenly distributed samples from an input sample set\n",
    "#\n",
    "# Inputs: Y    --> Sample matrix\n",
    "#         n, m --> Landmark matrix dimensions\n",
    "#\n",
    "# Output: idx  --> nxm Landmark matrix\n",
    "#\n",
    "def find_landmarks(Y, n, m):\n",
    "    xr = np.linspace(np.min(Y[:,0]), np.max(Y[:,0]), n)\n",
    "    yr = np.linspace(np.min(Y[:,1]), np.max(Y[:,1]), m)\n",
    "    xg, yg = np.meshgrid(xr, yr)\n",
    "    idx = [0]*(n*m)\n",
    "    for i, x, y in zip(range(n*m), xg.flatten(), yg.flatten()):\n",
    "        idx[i] = int(np.sum(np.abs(Y-np.array([x,y]))**2, axis=-1).argmin())\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the complete nearest neighbors array\n",
    "#\n",
    "# Inputs: X      --> training data\n",
    "#         n_nbrs --> the number of nearest neighbors to search for\n",
    "#         n_comp --> the number of components\n",
    "def compute_nearest_neighbors(X, n_nbrs, n_comp):\n",
    "    print(\"Computing nearest neighbors...\")\n",
    "    tree = neighbors.BallTree(X, leaf_size=n_comp)\n",
    "    dist, ind = tree.query(X, k=n_nbrs)\n",
    "    print(\"Complete nearest neighbor index: \", np.shape(ind))\n",
    "    return dist, ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Inputs: x --> the basis vector (784 x 1)\n",
    "#         E --> eta is the matrix of nearest neighbors (k x 784)\n",
    "# \n",
    "# Outputs: C --> the covariance matrix of the nearest neighbors of the vector x \n",
    "#\n",
    "# Iterate theough the nearest neighbors and compute the  \n",
    "#\n",
    "def calc_covariance(Eta):\n",
    "    #print(\"Calculate covariance:\")\n",
    "    #print(\"Eta: \", np.shape(Eta))\n",
    "    \n",
    "    # Compute the local covariance matrix\n",
    "    #C = np.cov(Eta)\n",
    "    C = mul(Eta.T, Eta)\n",
    "    #print(\"Local covariance matrix C: \", np.shape(C))\n",
    "\n",
    "    # Regularize the covariance matrix because otherwise it is singular\n",
    "    I = np.identity(np.shape(C)[0])\n",
    "    eps = .001 * np.trace(C)\n",
    "    C = C + eps * I\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Scale weight values for nearest neighbors\n",
    "#\n",
    "# Inputs:  wght --> the wight vector with non-neighbors blanked out\n",
    "# \n",
    "# Outputs: w    --> the adjusted weight vector    \n",
    "#\n",
    "def scale_neighbors(wght):\n",
    "    sumw = np.sum(wght)\n",
    "    w = wght / sumw\n",
    "    #print(\"Sum of weights: \", np.sum(w))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Build the matrix of nearest neighbors\n",
    "# \n",
    "# Inputs: X    --> the source data matrix X to get the neighbors from\n",
    "#         nbrs --> the list of neighbor indices\n",
    "#\n",
    "# Outputs: Eta --> the nearest neighbor matrix for Xi\n",
    "#\n",
    "# Use the neighbors list to get the corresponding vector from X and put the \n",
    "# vectors together in a nearest neighbor matrix\n",
    "#\n",
    "def build_nbrs_matrix(X, nbrs, k):\n",
    "    #print(\"Build nearest neighbors matrix...\")\n",
    "    # Build a matrix of the nearest neighbors\n",
    "    nbrs = np.delete(nbrs, 0, axis=0)   # remove Xi\n",
    "    #print(\"nbrs: \", np.shape(nbrs))\n",
    "    \n",
    "    D = np.shape(X)[1]                # set number of rows for Eta\n",
    "    N = np.shape(nbrs)[1]         # set columns for Eta. Subtract 1 because index from ball tree includes the vector itself\n",
    "    Eta = np.zeros([D, k])\n",
    "    \n",
    "    #print(\"D: \", D, \" N: \", N)\n",
    "    #print(\"Eta: \", np.shape(Eta))\n",
    "    \n",
    "    # Get each row vector from X corresponding to the nearest neighbor\n",
    "    for n in range(1, N):\n",
    "        Eta[:,n-1] = X[nbrs[0][n]]\n",
    "        #print(\"nbr \", nbrs[0][n])\n",
    "        \n",
    "        \n",
    "    #print(\"Eta: \", np.shape(Eta))    \n",
    "    #print(Eta)\n",
    "    return Eta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Center the matrix\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "def center_nbrs_matrix(x, Eta):\n",
    "    #print(\"Center the neighbors matrix...\")\n",
    "    n = np.shape(Eta)[1]\n",
    "    d = np.shape(x)[0]\n",
    "    #print(\"n: \", n)\n",
    "    #print(\"d: \", d)\n",
    "    #print(\"x: \", np.shape(x)) \n",
    "    sub = np.tile(x, (n,1))\n",
    "    #print(\"sub: \", np.shape(sub))\n",
    "    #print(\"Eta: \", np.shape(Eta))\n",
    "    eta = Eta - sub.T\n",
    "    return eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Determine the reconstruction weights for each X\n",
    "#\n",
    "# Inputs:  X    --> Data Matrix\n",
    "#          i    --> Index for vector xi we want to construct weights for\n",
    "#          tree --> nearest neighbors tree\n",
    "#          k    --> number of nearest neighbors  \n",
    "# \n",
    "# Outputs: W    --> the weight matrix\n",
    "#\n",
    "def construct_weight_vector(X, i, nbrs, k):\n",
    "    # Setup matrices and variables\n",
    "    #print(\"Construct weight matrix\")\n",
    "    #print(\"k = \", k)\n",
    "    #print(\"Image #\", i)\n",
    "    #print(\"Neighbors = \", nbrs)\n",
    "\n",
    "    # Build the matrix of nearest neighbors\n",
    "    Eta = build_nbrs_matrix(X, nbrs, k)\n",
    "    \n",
    "    # Center the data\n",
    "    Eta = center_nbrs_matrix(X[i,:], Eta)\n",
    "    \n",
    "    # Compute local covariance matrix for the vector v in X and all neighbors\n",
    "    C = calc_covariance(Eta)\n",
    "\n",
    "    # Solve the linear system with constraint that rows of weights sum to one\n",
    "    b = np.ones(np.shape(C)[1])  # build the constant vector\n",
    "    w = np.linalg.solve(C, b)    # compute solution\n",
    "    \n",
    "    # Apply first constraint to zero out non-neighbor weights\n",
    "    #w = clear_non_neighbors(nbrs, w)\n",
    "    \n",
    "    # Apply second constraint to scale valid neighbors\n",
    "    w = scale_neighbors(w)\n",
    "    \n",
    "    #print(\"Weight vector constructed...  w: \", np.shape(w))\n",
    "    #print(\"w = \", w)\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Calculate the sum of elements in a weight row for matrix M\n",
    "#\n",
    "# Inputs:   W\n",
    "#             \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "def sum_weight_row(W, i, j):\n",
    "    s = 0\n",
    "    for k in range(0, np.shape(W)[0]):\n",
    "        s = s + W[k,i] * W[k,j] \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "def compute_embedding_components(W, d):\n",
    "    #print(\"Compute embedding components:\")\n",
    "    #create sparse matrix M = (I-W)'*(I-W)\n",
    "    \n",
    "    # Create matrix M\n",
    "    print(\"Create matrix M...\")\n",
    "    d = np.shape(W)[0]\n",
    "    n = np.shape(W)[1]\n",
    "    #M = np.identity(n)\n",
    "    #M = np.zeros((d,n))\n",
    "    M = np.zeros(np.shape(W))\n",
    "    print(\"d: \", d, \" n: \", n)\n",
    "    print(\"M: \", np.shape(M))\n",
    "\n",
    "    for i in range(0, d):\n",
    "        for j in range(0, n):\n",
    "            if i == j:\n",
    "                delta = 1\n",
    "            else:\n",
    "                delta = 0\n",
    "            M[i,j] = delta - W[i,j] - W[i,j] + sum_weight_row(W, i, j)\n",
    "        #print(\"M[\",i,\",\",j,\"] = \", M[i,j])        \n",
    "\n",
    "\n",
    "    # \n",
    "    U, S, Vt = np.linalg.svd(M.T)\n",
    "    \n",
    "    #print(\"U: \", np.shape(U))\n",
    "    #print(U,\"\\n\")\n",
    "    #print(\"S: \", np.shape(S))\n",
    "    #print(\"Vt: \", np.shape(Vt))\n",
    "    \n",
    "    d = np.shape(U)[1]\n",
    "    Y = U[:,d-4:d-2].T\n",
    "    \n",
    "    print(\"Y: \", np.shape(Y))\n",
    "    print(Y)\n",
    "    \n",
    "    return Y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# TODO - We only have to implement this function, swap it with the manifold one below\n",
    "# Seek a low-rank projection on an input matrix\n",
    "#\n",
    "# Inputs: X            --> Input matrix to reduce\n",
    "#         n_neighbors  --> Maximum number of neighbors used for reconstruction\n",
    "#         n_components --> Maximum number of linearly independent components for reconstruction\n",
    "#\n",
    "# Output: Y            --> Reconstructed vectors in a lower rank\n",
    "#         err          --> (Optional implementation) Error margin of vectors\n",
    "#\n",
    "def locally_linear_embedding(X, n_neighbors, n_components):\n",
    "    \n",
    "    # Step 1: Find the nearest neighbors at for each sample\n",
    "    \n",
    "    # Testing\n",
    "    #tree = neighbors.BallTree(X, leaf_size=n_components)\n",
    "    #dist, ind = tree.query(X[:1], k=n_neighbors)\n",
    "    #print(\"ind: \", ind)\n",
    "    \n",
    "    # Primetime\n",
    "    #n_neighbors = n_neighbors + 1\n",
    "    dist, ind = compute_nearest_neighbors(X, n_neighbors + 1, n_components)\n",
    "    \n",
    "    # Step 2: Construct the weight matrix\n",
    "    D = np.shape(X)[0]\n",
    "    N = np.shape(X)[1]\n",
    "    W = np.zeros((n_neighbors, D))  # subtract 1 from D because nearest neighbor returns the vector itself\n",
    "    \n",
    "    print(\"X: \", np.shape(X))\n",
    "    print(\"N: \", N, \" D: \", D)\n",
    "    print(\"W: \", np.shape(W))\n",
    "\n",
    "    # Loop through each image and construct its weight matrix \n",
    "    for i in range(0, D):\n",
    "        #print(\"Image: \",i)\n",
    "        w = construct_weight_vector(X, i, ind, n_neighbors)\n",
    "        W[:,i] = w[:]\n",
    "    \n",
    "    # Step 3: Compute vectors that are reconstructed by weights\n",
    "    Y = compute_embedding_components(W, 2)\n",
    "    \n",
    "    # Calculate the error\n",
    "    \n",
    "    err = 0.001    # placeholder\n",
    "    return Y, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN\n",
    "# -----------------------------------------------------------------------------\n",
    "np.set_printoptions(precision=2, edgeitems=10)\n",
    "\n",
    "# Extract mnist data from files\n",
    "raw_train = read_idx(\"train-images-idx3-ubyte.gz\")\n",
    "train_data = np.reshape(raw_train, (60000, 28*28))\n",
    "train_label = read_idx(\"train-labels-idx1-ubyte.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing nearest neighbors...\n"
     ]
    }
   ],
   "source": [
    "# Train algorithm and calculate landmark graph\n",
    "X = train_data[train_label == 8]\n",
    "\n",
    "# Test by using scikit class\n",
    "#Y, err = manifold.locally_linear_embedding(X, n_neighbors=10, n_components=2)\n",
    "\n",
    "# Verify by using our custom method\n",
    "Y, err = locally_linear_embedding(X, n_neighbors=10, n_components=2)\n",
    "\n",
    "\n",
    "landmarks = find_landmarks(Y, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the clustered data with landmarks overlaid\n",
    "plt.scatter(Y[:,0], Y[:,1])\n",
    "plt.scatter(Y[landmarks,0], Y[landmarks,1])\n",
    "\n",
    "# Show the landmark samples in a 5x5 grid\n",
    "fig = plt.figure(figsize=(15,15))\n",
    "for i in range(len(landmarks)):\n",
    "    ax = fig.add_subplot(5, 5, i+1)\n",
    "    imgplot = ax.imshow(np.reshape(X[landmarks[i]], (28,28)), cmap=plt.cm.get_cmap(\"Greys\"))\n",
    "    imgplot.set_interpolation(\"nearest\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
